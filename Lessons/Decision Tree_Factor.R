getwd()

setwd("C:/Users/AzatR/Documents/Decision_Tree")
#?????? ?????????
rm(list=ls())

#???????? ??????
all.data <- read.csv("train.csv")

#???????
train <- all.data

#???????? ?? ????????????? ????????
apply(all.data, 2, function(x) sum(is.na(x)))

#??????? ??? id ? target
train_cols <- names(train[,-c(1,2)])

#??????? ??? ?????? ??????????? ?????
p_values <- data.frame(vars = names(train[,-c(1,2)]), p_value= NA)

#???? ?????????? ? ??????? ???????? p-value ?? ??????????? T-????? ??? ?????? ???????.
#? ?-????? ???????????? ????????????? ???????? ???????? ????? ????????? ? 0 ? 1 ? ????????? ??????????
for (i in 1:(ncol(train)-2)){
  p_values[i,2] <- t.test(train[,train_cols[i]][train$target == 0], train[,train_cols[i]][train$target == 1])$p.value
}

p_values$vars <- as.character(p_values$vars)


#? ????? ??????? ???????????? ????????, ??? p-value ?????? 5%, ?.? ????????????? ???????? ???????
super_cols <- p_values[p_values$p_value < 0.05,]


#?? ???????????? ???????? ????????? ?????? ????????????? ???????? ??????? ?? ??????????? ?-????? ? ???????? ? ??? ??????? id ? target 
train_sign <- cbind(train[,1:2], train[,super_cols$vars])

cats <- grep('_cat', names(train_sign))


# for (i in cats){
#   train_sign[,i] <- as.factor(train_sign[,i])
# }


scaled_train_sign <- train_sign
#scaled_train_sign[,cats] <- NULL
scaled_train_sign$id <- NULL
scaled_train_sign$target <- NULL

scaled_train_sign <- scale(scaled_train_sign)
scaled_train_sign <- as.data.frame(cbind(id=train_sign$id, target = train_sign$target, scaled_train_sign))

index <- sample(1:nrow(scaled_train_sign), round(nrow(scaled_train_sign)*0.7), replace=FALSE)
trainset <- scaled_train_sign[index, -1]
testset <- scaled_train_sign[-index, -1]


prop.table(table(trainset$target))
prop.table(table(testset$target))


trainset_balanced_both <- trainset

trainset_balanced_both <- ovun.sample(target~.,data=trainset, method = "both")$data
table(trainset_balanced_both$target)
prop.table(table(trainset_balanced_both$target))


lm.fit <- glm(target~., data = trainset_balanced_both, family = binomial())
summary(lm.fit)


pr.lm <- predict(lm.fit, testset)
MSE.lm <- sum((pr.lm-testset$target)^2)/nrow(testset)

roc.curve(testset$target, pr.lm)







View(pr.lm)












library(rpart)
library(ROSE)



trainset_balanced_both <- ovun.sample(target~.,data=trainset, method = "both")$data
table(trainset_balanced_both$target)
prop.table(table(trainset_balanced_both$target))

fit_both <- rpart(target~., data=trainset_balanced_both)

predicted_value_both <- predict(fit_both, newdata = testset)

accuracy.meas(testset$target, predicted_value_both)

roc.curve(testset$target, predicted_value_both)



trainset_balanced_under <- ovun.sample(target~.,data=trainset, method = "under")$data
table(trainset_balanced_under$target)
prop.table(table(trainset_balanced_under$target))

fit_under <- rpart(target~., data=trainset_balanced_under)

predicted_value_under <- predict(fit_under, newdata = testset)


accuracy.meas(testset$target, predicted_value_under)

roc.curve(testset$target, predicted_value_under)






trainset_balanced_over <- ovun.sample(target~.,data=trainset, method = "over")$data
table(trainset_balanced_over$target)
prop.table(table(trainset_balanced_over$target))

fit_over <- rpart(target~., data=trainset_balanced_over)

predicted_value_over <- predict(fit_over, newdata = testset)

accuracy.meas(testset$target, predicted_value_over)

roc.curve(testset$target, predicted_value_over)








trainset_balanced_sdg <- ROSE(target~., data=trainset, seed = 1)$data
table(trainset_balanced_sgd$target)
prop.table(table(trainset_balanced_sgd$target))

fit_sgd <- rpart(target~., data=trainset_balanced_sgd)

predicted_value_sgd <- predict(fit_sgd, newdata = testset)

accuracy.meas(testset$target, predicted_value_sgd)

roc.curve(testset$target, predicted_value_sgd)


